\chapter{Theory}

Interactomic Potential Energy Surface (PES) is an important property of the
system
that enables us to explain and predict materials properties such as interfacial
energies, thermal expansion, cohesion, surface tension as well as chemical
reactions.
Representing PES accurately and efficiently is a major goal in molecular
modelling.
Existing approaches to PES modelling includes ab-initio models based on DFT,
empirical potentials fitted with experimental data, and the relatively new
machine learning based approach. The first one is accurate, parameter-free, and
transferable but has bad scaling with system size. The second one is
computationally efficient but has limited accuracy and transferability.
The third one combines both the advantages of the two previous approaches in
that it efficiently represents the PES for a
wide variety of systems with the level of accuracy of ab initio quantum
mechanics
models and scales for large systems.

% https://en.wikipedia.org/wiki/Interatomic_potential
This work will focus on a particular scheme for molecular modelling, the deep
neural network
potential molecular dynamics.

\section{Basics of Machine Learning}
Before dealing with deep potential molecular dynamics, one must have a basic
understanding on the principles of machine learning. Machine Learning (ML)
falls
under
the umbrella
term of Artificial Intelligence
(AI)
that focuses on developing algorithms that enable computers to learn from and
make decisions based on data. It is based on the idea that systems can
automatically improve their performance on a task through experience without
human intervention. The algorithm will understand the data by deconstructing it
in terms of hierarchy of concepts, with each concept defined through its
relation to simpler concepts. This allows the algorithm to learn complicated
concepts by building from simpler ones. Tasks such as classification,
regression, transcription, clustering, translation, to name a few can be solved
by ML.

% https://www.deeplearningbook.org/contents/intro.html
% https://www.deeplearningbook.org/contents/ml.html

Regression learning works by allowing the program to fit an input of dimension
$\mathfrak{R}^n$ to an output of lower dimension $\mathfrak{R}^m$ by applying a
mapping function $f$.
Regression learning is an example of supervised learning since it
involves training a model on a labeled dataset. In practice, the labeled data
set is split into two: the training/learning and the testing/validation
data. The first one is feed to the algorithm while the second one is used to
validate the accuracy of the prediction.

Deep Learning is a type of ML that mimics the function of a
neuron in the living systems. It is divided into layers that constitutes the
input, output and multiple hidden layers where each layers contains collection
of
`neurons' or nodes as schematically shown in Figure \ref{fig:DL}. An algorithm
with one
hidden layer is
considered an Artificial Neural Network (ANN). Specifically, the algorithm is a
subset of Regression learning that maps an input to an output. Deep forwarded
network, also called
feed-forward neural network, refers to the idea that information moves in only
one direction from input, through the hidden layers,  to the output.  The goal
of a feedforward network is to approximate the mapping $y = f(x; w)$ of input
vector $x$ to an output vector $y$ by optimizing the values of the
parameters/weights $w$. Networking works by applying composition of many
different
functions. For a network with  $N$ layers depth, $N$ functions $f^1, f^2,
    \cdots, f^N$ will be
chained in succession to form $f(x) = f^N(\cdots f^2(f^1(x)))$. The innermost
function
refers to the first layer while the outermost function refers to the output
layer. Those functions that are in between refer to hidden layers since their
outputs are not desired.

% change graph 
% https://www.bmc.com/blogs/deep-neural-network/
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{images/DL.png}
    \caption{Typical configuration of a Deep Learning algorithm with 2 hidden
        layers that maps a $\mathfrak{R}^3$ input vector to a scalar output
        vector.}
    \label{fig:DL}
\end{figure}

To explain how each functions work, we look closely to the mathematical
interpretation of a neuron, as schematically shown in
Figure~\ref{fig:neuron_struc}. For a given artificial neuron $j$, let there be
$n+1$ inputs with signals $x_0$ through $x_n$ and weights $w_{0j}$ through
$w_{nj}$. The $x_0$ input is assigned the value +1, which makes it a bias input
with $w_{0j}$ = $b_j$. There will be $n$ actual inputs to the neuron: from
$x_1$ to $x_n$. The inputs will be weighted sum and the result is used as an
argument of the threshold function or activation function $\varphi$. Once the
function reaches a threshold value $\theta_j$ or more, it will give the output
or activation $o_j$ of the
$j$th neuron. Mathematically,

\begin{equation}
    o_j =   \varphi \left(\sum_{i=0}^{n} w_{ij} x_i \right)
\end{equation}

Typical activation functions are Heaviside function, sigmoid, and rectified
linear functions (ReLu).

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\linewidth]{images/artificial_neuron.pdf}
    \caption{The mathematical model of a neuron as first introduced by
        McCulloch and Pitts \cite{mcculloch1943logical}. Image taken at
        commons.wikimedia.org/wiki/File:Artificial\_neuron\_structure.svg}
    \label{fig:neuron_struc}
\end{figure}

One way to assess the performance of the training model is to compute the loss
function, or cost function, $\mathcal{L}$ with respect to the weights. A simple
choice is to compute the mean squared error
(MSE)
between the predicted $\hat{y}^{(\text{test})}$ and actual $y^{(\text{test})}$
value within the testing
dataset.

\begin{equation}
    \mathcal{L}^{(\text{test})}(w) = MSE^{(\text{test})} = \frac{1}{M} \sum_i^M
    \left(
    \hat{y}_i^{(\text{test})} -
    y_i^{(\text{test})} \right)^2  = \frac{1}{M} \sum_i^M
    \mathcal{L}^{(\text{test})}_i
\end{equation}

where $M$ is the number of test examples in the dataset. An algorithm should be
introduced to minimize the error  while allowing to gain
experience by incorporating a training dataset.
An intuitive way is to minimize the MSE on the training dataset with respect to
the weights by carrying out
the minimization problem called Gradient Descent

\begin{equation}
    \nabla_w \text{MSE}_\text{train} \approx 0
\end{equation}

The weights are updated by subtracting a factor proportional to the
gradient of the loss function.

\begin{equation}
    w_{n+1} = w_n - \epsilon  \grad_w \mathcal{L}(w)
\end{equation}

where $\epsilon$ is the learning rate and $n$ is the iteration step. Stochastic
Gradient Descent extends the well-known Gradient Descent algorithm. Instead of
computing the
actual gradient, which is computationally expensive for large training
datasets,  it is replaced
by an approximate gradient of a random subset of the training data. The loss
function is minimized by taking  the average gradient with respect to the
weights for $M'$ random minibatches of examples from the training set

\begin{align}
    \grad_w \mathcal{L}(w) \approx \frac{1}{M'} \sum_{i=1}^{M'} \grad_w L_i
\end{align}
where $L_i$ is the loss function of a specific training example $i$.

The stochastic gradient descent does a good job in reducing the computational
time, but the learning process can still be improved by implementing the
back-propagation algorithm. The algorithm works by computing the gradient of
the loss function with respect to each weights by utilizing chain rules in
backward fashion, from last layer to the first.

Without going to full derivation, the idea is to include all parameters that
causes variation in the loss function. This includes changes in the weights,
biases and the activations of the previous layer. Consider the case of a
particular neuron
$j$ in the $L$th layer. Neurons in $(L-1)$th layer with higher activation will
be more sensitive
to variation which implies weight is proportional to the ac

% rephrase
Deep learning continues to evolve rapidly, driven by advances in
computational power, availability of large datasets, and innovative algorithms.
It holds the promise of transforming various aspects of human life and industry
by enabling more intelligent, autonomous systems.

\section{Deep Neural Molecular Dynamics}

Global Coordinate matrix

\begin{equation}
    \mathcal{R} =  \mqty( x_1 & y_1 & z_1 \\ x_2 & y_2 & z_2 \\ \vdots & \ddots
    &
    \vdots \\
    x_N & y_N & z_N)
\end{equation}

Relative Coordinate Matrix with respect to atom $i$

\begin{equation}
    \mathcal{R}^i =  \mqty( x_{1i} & y_{1i} & z_{1i} \\ x_{2i} & y_{2i} &
    z_{2i}
    \\ \vdots & \ddots
    &
    \vdots \\
    x_{N_i i} & y_{N_i i} & z_{N_i i})
\end{equation}

Renormalized Coordinate Matrix
\begin{equation}
    \tilde{\mathcal{R}^i} =  \mqty( s(r_{1i}) &
    \frac{s(r_{1i}) x_{1i}}{r_{1i}}
    &	 \frac{s(r_{1i}) y_{1i}}{r_{1i}} &
    \frac{s(r_{1i}) z_{1i}}{r_{1i}} \\
    s(r_{2i}) &
    \frac{s(r_{2i}) x_{2i}}{r_{2i}}
    &	 \frac{s(r_{2i}) y_{2i}}{r_{2i}} &
    \frac{s(r_{2i}) z_{2i}}{r_{2i}}
    \\ \vdots & \vdots & \vdots
    &
    \vdots \\
    s(r_{N_i i}) &
    \frac{s(r_{N_i i}) x_{N_i i}}{r_{N_i i}}
    &	 \frac{s(r_{N_i i}) y_{N_i i}}{r_{N_i i}} &
    \frac{s(r_{N_i i}) z_{N_i i}}{r_{N_i i}} )
\end{equation}

where $s(r)$ is a smooth switching function defined as

\begin{equation}
    s(r) = \begin{cases}
        \frac{1}{r}                                   & , r   < r_s        \\
        \frac{1}{r} \left[x^3 (-6x^2+15x-10)+1\right] & , r_s \leq r < r_c \\
        0                                             & , r   \geq r_c
    \end{cases}
\end{equation}

where $x = \frac{r- r_s}{r_c-r_s}$, $r_c$ is the cutoff radius and $r_s$ is the
distance from atom $i$ where smoothing is applied.
